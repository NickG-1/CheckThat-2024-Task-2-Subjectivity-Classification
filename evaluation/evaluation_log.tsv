f1_macro	rel_confusion_matrix	model_info	feature_extractor_info	preprocessing_info	additional_info
0.639133006591178	"[[0.78301887 0.21698113]
 [0.48672566 0.51327434]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on SBERT	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.649097655591162	"[[0.78301887 0.21698113]
 [0.46902655 0.53097345]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on SBERT	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.488118426178418	"[[0.97169811 0.02830189]
 [0.82300885 0.17699115]]"	RandomForestClassifier()	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on SBERT	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.52701980910801	"[[0.9245283  0.0754717 ]
 [0.75221239 0.24778761]]"	RandomForestClassifier()	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on SBERT	preprocessing: oversampling, lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.620212699274984	"[[0.68867925 0.31132075]
 [0.44247788 0.55752212]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on SBERT	preprocessing: oversampling, lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.649097655591162	"[[0.78301887 0.21698113]
 [0.46902655 0.53097345]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on SBERT	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.61737236038912	"[[0.83962264 0.16037736]
 [0.56637168 0.43362832]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), StandardScaler on tfidf, paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on SBERT	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.61737236038912	"[[0.83962264 0.16037736]
 [0.56637168 0.43362832]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on both	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.547852147852148	"[[0.8490566  0.1509434 ]
 [0.68141593 0.31858407]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on both, PCA(n_components=0.95)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.326153846153846	"[[1. 0.]
 [1. 0.]]"	RandomForestClassifier()	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler on both, PCA(n_components=0.95)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.675690895818125	"[[0.67924528 0.32075472]
 [0.32743363 0.67256637]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7cb61ab91870>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.60444954420858	"[[0.77358491 0.22641509]
 [0.53982301 0.46017699]]"	"XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)"	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7cb61ab91870>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.326153846153846	"[[1. 0.]
 [1. 0.]]"	MultinomialNB()	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7cb61ab91870>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.586853763486445	"[[0.74528302 0.25471698]
 [0.54867257 0.45132743]]"	MLPClassifier(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7cb61ab91870>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	
0.684931506849315	"[[0.70754717 0.29245283]
 [0.33628319 0.66371681]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7cb61ab91870>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	
0.680305305305305	"[[0.71698113 0.28301887]
 [0.3539823  0.6460177 ]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7cb61ab91870>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	sample weights: 1.0 if solved_conflict else 0.8
0.680358632193495	"[[0.70754717 0.29245283]
 [0.34513274 0.65486726]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7cb61ab91870>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	
0.657505682173614	"[[0.68867925 0.31132075]
 [0.37168142 0.62831858]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, KeyedVectors<vector_size=300, 3000000 keys>, MinMaxScaler on Word2Vec, SelectKBest(k=3000, score_func=<function chi2 at 0x7072cf5b52d0>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	
0.666666666666667	"[[0.68867925 0.31132075]
 [0.3539823  0.6460177 ]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, KeyedVectors<vector_size=300, 3000000 keys>, MinMaxScaler on Word2Vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7072cf5b52d0>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	
0.684826363541558	"[[0.72641509 0.27358491]
 [0.3539823  0.6460177 ]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, KeyedVectors<vector_size=300, 3000000 keys>, MinMaxScaler on Word2Vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7072cf5b52d0>)	preprocessing: lowercase, replace quotes with <quote>, remove links and usernames, lemmatize, remove special characters except for ? and !, replace numbers with <num>	
0.679556856187291	"[[0.75471698 0.24528302]
 [0.38938053 0.61061947]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, KeyedVectors<vector_size=300, 3000000 keys>, MinMaxScaler on Word2Vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7072cf5b52d0>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	
0.698321923526465	"[[0.75471698 0.24528302]
 [0.3539823  0.6460177 ]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, KeyedVectors<vector_size=300, 3000000 keys>, MinMaxScaler on Word2Vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7de8da3c9360>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.661754883953916	"[[0.71698113 0.28301887]
 [0.38938053 0.61061947]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, SelectKBest(k=2000, score_func=<function chi2 at 0x7b22b37b4ee0>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.666221266467628	"[[0.6509434  0.3490566 ]
 [0.31858407 0.68141593]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x77d68d4f6b60>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x77d68dfa96c0>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.661754883953916	"[[0.71698113 0.28301887]
 [0.38938053 0.61061947]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x77d69ddcf400>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x77d68dfa96c0>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.661528822055138	"[[0.64150943 0.35849057]
 [0.31858407 0.68141593]]"	SVC(kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7229a60fee30>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7229a6a85120>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.698321923526465	"[[0.75471698 0.24528302]
 [0.3539823  0.6460177 ]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7229b6abf8e0>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7229a6a85120>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.698472963951936	"[[0.74528302 0.25471698]
 [0.34513274 0.65486726]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7228bcd01e70>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7229a6a85120>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords, sample weights: 1.0 if solved_conflict else 0.8
0.693834115805947	"[[0.74528302 0.25471698]
 [0.3539823  0.6460177 ]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x734438833cd0>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7344395252d0>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords, sample weights: 1.0 if solved_conflict else 0.6
0.693655134977138	"[[0.67924528 0.32075472]
 [0.2920354  0.7079646 ]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x734449190520>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7344395252d0>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.692808541819324	"[[0.78301887 0.21698113]
 [0.38938053 0.61061947]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x734327bb4f40>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7344395252d0>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.677941176470588	"[[0.79245283 0.20754717]
 [0.42477876 0.57522124]]"	LogisticRegression(C=0.07276405979294862, max_iter=2000, solver='liblinear')	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7599b80d2650>>, then MinMaxScaler on word2vec, SelectKBest(k=2401, score_func=<function chi2 at 0x7599a7ea93f0>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.694651005577151	"[[0.83962264 0.16037736]
 [0.43362832 0.56637168]]"	LogisticRegression(C=0.07276405979294862, max_iter=1000, solver='liblinear')	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x797c385199f0>>, then MinMaxScaler on word2vec, SelectKBest(k=2401, score_func=<function chi2 at 0x797c29d94e50>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.66261475150364	"[[0.80188679 0.19811321]
 [0.46017699 0.53982301]]"	SVC(C=0.07276405979294862, kernel='linear', probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x797b183793f0>>, then MinMaxScaler on word2vec, SelectKBest(k=2401, score_func=<function chi2 at 0x797c29d94e50>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.652787049399199	"[[0.69811321 0.30188679]
 [0.38938053 0.61061947]]"	SVC(C=8.47271111011792, coef0=6.342276287023357, degree=4)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x73405aaef7f0>>, then MinMaxScaler on word2vec, SelectKBest(k=2130, score_func=<function chi2 at 0x73404b3c8e50>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.677941176470588	"[[0.79245283 0.20754717]
 [0.42477876 0.57522124]]"	SVC(C=8.47271111011792, coef0=6.342276287023357, degree=4)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x73405b5a2320>>, then MinMaxScaler on word2vec, SelectKBest(k=2130, score_func=<function chi2 at 0x73404b3c8e50>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.64601045405882	"[[0.75471698 0.24528302]
 [0.45132743 0.54867257]]"	SVC(C=8.47271111011792, coef0=6.342276287023357, degree=4, probability=True)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7573bf4ebe50>>, then MinMaxScaler on word2vec, SelectKBest(k=2130, score_func=<function chi2 at 0x7573afda5000>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.674822761779284	"[[0.75471698 0.24528302]
 [0.39823009 0.60176991]]"	LogisticRegression(C=0.07276405979294862, max_iter=1000, solver='liblinear')	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7573bff999f0>>, then MinMaxScaler on word2vec, SelectKBest(k=2130, score_func=<function chi2 at 0x7573afda5000>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.626819956428895	"[[0.8490566  0.1509434 ]
 [0.55752212 0.44247788]]"	LogisticRegression(C=0.07276405979294862, max_iter=1000, solver='liblinear')	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7572c641e260>>, then MinMaxScaler on word2vec, SelectKBest(k=2401, score_func=<function chi2 at 0x7573afda5000>)	preprocessing: oversampling .85, lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.658049965301874	"[[0.89622642 0.10377358]
 [0.53982301 0.46017699]]"	LogisticRegression(C=0.07276405979294862, max_iter=1000, solver='liblinear')	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7572c920d840>>, then MinMaxScaler on word2vec, SelectKBest(k=2401, score_func=<function chi2 at 0x7573afda5000>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
0.698321923526465	"[[0.75471698 0.24528302]
 [0.3539823  0.6460177 ]]"	LogisticRegression(max_iter=1000)	TfidfVectorizer(), paraphrase-multilingual-MiniLM-L12-v2, StandardScaler then MinMaxScaler on sbert, <bound method FeauturesExtractor.applyWord2Vec of <__main__.FeauturesExtractor object at 0x7572c641e050>>, then MinMaxScaler on word2vec, SelectKBest(k=2000, score_func=<function chi2 at 0x7573afda5000>)	preprocessing: lowercase, replace quotes with <quote>, remove links, usernames and stopwords, lemmatize, remove special characters except for ? and !, replace numbers with <num>	erased auxilariy verbs from stopwords
